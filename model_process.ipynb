{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import helper\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['DejaVu Serif', 'Arial', 'Liberation Serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_data, test_data, train_mean, train_std \u001b[38;5;241m=\u001b[39m helper\u001b[38;5;241m.\u001b[39mpreprocess_data_array(\u001b[43mX\u001b[49m, number_of_folds\u001b[38;5;241m=\u001b[39mn_folds, current_fold_id\u001b[38;5;241m=\u001b[39mi)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_asd = np.load('./output/TRIAL_NC_2_23/fold0_cbt.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgn_asd = np.load('./output/DGN_ASD_ALL/fold0_cbt.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Strengths: 2.1292613\n",
      "Node Strengths: 1.5753807\n"
     ]
    }
   ],
   "source": [
    "node_strengths = np.sum(new_asd, axis=1)\n",
    "\n",
    "print(\"Node Strengths new:\", np.average(node_strengths))\n",
    "\n",
    "node_strengths = np.sum(dgn_asd, axis=1)\n",
    "\n",
    "print(\"Node Strengths dgn:\", np.average(node_strengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvector Centrality: 0.028571427\n"
     ]
    }
   ],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(new_asd)\n",
    "\n",
    "# Find the eigenvector corresponding to the largest eigenvalue\n",
    "largest = np.argmax(eigenvalues)\n",
    "eigenvector_centrality = np.abs(eigenvectors[:, largest])\n",
    "\n",
    "# Normalize the eigenvector centrality scores\n",
    "eigenvector_centrality = eigenvector_centrality / np.sum(eigenvector_centrality)\n",
    "\n",
    "print(\"Eigenvector Centrality:\", np.average(eigenvector_centrality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvector Centrality: 0.028571432\n"
     ]
    }
   ],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(dgn_asd)\n",
    "\n",
    "# Find the eigenvector corresponding to the largest eigenvalue\n",
    "largest = np.argmax(eigenvalues)\n",
    "eigenvector_centrality = np.abs(eigenvectors[:, largest])\n",
    "\n",
    "# Normalize the eigenvector centrality scores\n",
    "eigenvector_centrality = eigenvector_centrality / np.sum(eigenvector_centrality)\n",
    "\n",
    "print(\"Eigenvector Centrality:\", np.average(eigenvector_centrality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness Centrality: 0.0748663101604278\n"
     ]
    }
   ],
   "source": [
    "G = nx.from_numpy_array(new_asd)\n",
    "\n",
    "betweenness_centrality = nx.betweenness_centrality(G, normalized=True, weight='weight')\n",
    "\n",
    "centrality_values = list(betweenness_centrality.values())\n",
    "\n",
    "average_centrality = np.sum(centrality_values)\n",
    "\n",
    "print(\"Betweenness Centrality:\", average_centrality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness Centrality: 0.0303030303030303\n"
     ]
    }
   ],
   "source": [
    "G = nx.from_numpy_array(dgn_asd)\n",
    "\n",
    "betweenness_centrality = nx.betweenness_centrality(G, normalized=True, weight='weight')\n",
    "\n",
    "\n",
    "centrality_values = list(betweenness_centrality.values())\n",
    "\n",
    "average_centrality = np.sum(centrality_values)\n",
    "\n",
    "print(\"Betweenness Centrality:\", average_centrality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbt_nc_0 = np.load('./output/THREE_LOSSES_229_NC_ALL/fold0_cbt.npy')\n",
    "cbt_nc_1 = np.load('./output/THREE_LOSSES_229_NC_ALL/fold1_cbt.npy')\n",
    "cbt_nc_2 = np.load('./output/THREE_LOSSES_229_NC_ALL/fold2_cbt.npy')\n",
    "cbt_nc_3 = np.load('./output/THREE_LOSSES_229_NC_ALL/fold3_cbt.npy')\n",
    "cbt_nc_4 = np.load('./output/THREE_LOSSES_229_NC_ALL/fold4_cbt.npy')\n",
    "cbt_asd_0 = np.load('./output/THREE_LOSSES_229/fold0_cbt.npy')\n",
    "cbt_asd_1 = np.load('./output/THREE_LOSSES_229/fold1_cbt.npy')\n",
    "cbt_asd_2 = np.load('./output/THREE_LOSSES_229/fold2_cbt.npy')\n",
    "cbt_asd_3 = np.load('./output/THREE_LOSSES_229/fold3_cbt.npy')\n",
    "cbt_asd_4 = np.load('./output/THREE_LOSSES_229/fold4_cbt.npy')\n",
    "cbt_nc_test_0 = np.load('./output/test_data/fold0_cbt_nc.npy')\n",
    "cbt_nc_test_1 = np.load('./output/test_data/fold1_cbt_nc.npy')\n",
    "cbt_nc_test_2 = np.load('./output/test_data/fold2_cbt_nc.npy')\n",
    "cbt_nc_test_3 = np.load('./output/test_data/fold3_cbt_nc.npy')\n",
    "cbt_nc_test_4 = np.load('./output/test_data/fold4_cbt_nc.npy')\n",
    "cbt_asd_test_0 = np.load('./output/test_data/fold0_cbt_asd.npy')\n",
    "cbt_asd_test_1 = np.load('./output/test_data/fold1_cbt_asd.npy')\n",
    "cbt_asd_test_2 = np.load('./output/test_data/fold2_cbt_asd.npy')\n",
    "cbt_asd_test_3 = np.load('./output/test_data/fold3_cbt_asd.npy')\n",
    "cbt_asd_test_4 = np.load('./output/test_data/fold4_cbt_asd.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbt_nc_0 = np.load('./output/ADHD_THREE_LOSS_TRAIN/fold0_cbt.npy')\n",
    "cbt_nc_1 = np.load('./output/ADHD_THREE_LOSS_TRAIN/fold1_cbt.npy')\n",
    "cbt_nc_2 = np.load('./output/ADHD_THREE_LOSS_TRAIN/fold2_cbt.npy')\n",
    "cbt_nc_3 = np.load('./output/ADHD_THREE_LOSS_TRAIN/fold3_cbt.npy')\n",
    "cbt_nc_4 = np.load('./output/ADHD_THREE_LOSS_TRAIN/fold4_cbt.npy')\n",
    "cbt_asd_0 = np.load('./output/LMCI_THREE_LOSS_TRAIN/fold0_cbt.npy')\n",
    "cbt_asd_1 = np.load('./output/LMCI_THREE_LOSS_TRAIN/fold1_cbt.npy')\n",
    "cbt_asd_2 = np.load('./output/LMCI_THREE_LOSS_TRAIN/fold2_cbt.npy')\n",
    "cbt_asd_3 = np.load('./output/LMCI_THREE_LOSS_TRAIN/fold3_cbt.npy')\n",
    "cbt_asd_4 = np.load('./output/LMCI_THREE_LOSS_TRAIN/fold4_cbt.npy')\n",
    "cbt_nc_test_0 = np.load('./output/ADHD_THREE_LOSS_TEST/fold0_cbt.npy')\n",
    "cbt_nc_test_1 = np.load('./output/ADHD_THREE_LOSS_TEST/fold1_cbt.npy')\n",
    "cbt_nc_test_2 = np.load('./output/ADHD_THREE_LOSS_TEST/fold2_cbt.npy')\n",
    "cbt_nc_test_3 = np.load('./output/ADHD_THREE_LOSS_TEST/fold3_cbt.npy')\n",
    "cbt_nc_test_4 = np.load('./output/ADHD_THREE_LOSS_TEST/fold4_cbt.npy')\n",
    "cbt_asd_test_0 = np.load('./output/LMCI_THREE_LOSS_TEST/fold0_cbt.npy')\n",
    "cbt_asd_test_1 = np.load('./output/LMCI_THREE_LOSS_TEST/fold1_cbt.npy')\n",
    "cbt_asd_test_2 = np.load('./output/LMCI_THREE_LOSS_TEST/fold2_cbt.npy')\n",
    "cbt_asd_test_3 = np.load('./output/LMCI_THREE_LOSS_TEST/fold3_cbt.npy')\n",
    "cbt_asd_test_4 = np.load('./output/LMCI_THREE_LOSS_TEST/fold4_cbt.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(A):\n",
    "    symmetric_matrix = (A + A.T)/2\n",
    "    upper_triangle = np.triu(symmetric_matrix, k=1)\n",
    "    vectorized_form = upper_triangle[upper_triangle != 0]\n",
    "    return vectorized_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_nc_0 = vectorize(cbt_nc_0)\n",
    "vectorized_nc_1 = vectorize(cbt_nc_1)\n",
    "vectorized_nc_2 = vectorize(cbt_nc_2)\n",
    "vectorized_nc_3 = vectorize(cbt_nc_3)\n",
    "vectorized_nc_4 = vectorize(cbt_nc_4)\n",
    "\n",
    "vectorized_asd_0 = vectorize(cbt_asd_0)\n",
    "vectorized_asd_1 = vectorize(cbt_asd_1)\n",
    "vectorized_asd_2 = vectorize(cbt_asd_2)\n",
    "vectorized_asd_3 = vectorize(cbt_asd_3)\n",
    "vectorized_asd_4 = vectorize(cbt_asd_4)\n",
    "\n",
    "vectorized_nc_test_0 = vectorize(cbt_nc_test_0)\n",
    "vectorized_nc_test_1 = vectorize(cbt_nc_test_1)\n",
    "vectorized_nc_test_2 = vectorize(cbt_nc_test_2)\n",
    "vectorized_nc_test_3 = vectorize(cbt_nc_test_3)\n",
    "vectorized_nc_test_4 = vectorize(cbt_nc_test_4)\n",
    "\n",
    "vectorized_asd_test_0 = vectorize(cbt_asd_test_0)\n",
    "vectorized_asd_test_1 = vectorize(cbt_asd_test_1)\n",
    "vectorized_asd_test_2 = vectorize(cbt_asd_test_2)\n",
    "vectorized_asd_test_3 = vectorize(cbt_asd_test_3)\n",
    "vectorized_asd_test_4 = vectorize(cbt_asd_test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6245791245791246\n",
      "Sensitivity: 0.27946127946127947\n",
      "Specificity: 0.9696969696969697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.97      0.72       594\n",
      "           1       0.90      0.28      0.43       594\n",
      "\n",
      "    accuracy                           0.62      1188\n",
      "   macro avg       0.74      0.62      0.57      1188\n",
      "weighted avg       0.74      0.62      0.57      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "train_data1 = vectorized_nc_2.reshape(-1, 1)\n",
    "train_data2 = vectorized_asd_2.reshape(-1, 1)\n",
    "test_data1 = vectorized_nc_test_2.reshape(-1, 1)\n",
    "test_data2 = vectorized_asd_test_2.reshape(-1, 1)\n",
    "\n",
    "# Labels\n",
    "y_train = np.array([0]*594 + [1]*594)  # 0 for group 1, 1 for group 2\n",
    "y_test = np.array([0]*594 + [1]*594)\n",
    "\n",
    "# Combine data for training and testing\n",
    "X_train = np.vstack((train_data1, train_data2))\n",
    "X_test = np.vstack((test_data1, test_data2))\n",
    "\n",
    "# Train the SVM\n",
    "clf = SVC(kernel='linear', class_weight='balanced')  # Using a linear kernel and balanced class weights\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(f'Sensitivity: {sensitivity}')\n",
    "print(f'Specificity: {specificity}')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.515993265993266\n",
      "Sensitivity: 0.9747474747474747\n",
      "Specificity: 0.05723905723905724\n",
      "F1 Score: 0.668205424120023\n",
      "AUC Score: 0.4730894806652382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Combine and reshape data for training and testing\n",
    "train_data1 = vectorized_nc_2.reshape(-1, 1)\n",
    "train_data2 = vectorized_asd_1.reshape(-1, 1)\n",
    "test_data1 = vectorized_nc_test_1.reshape(-1, 1)\n",
    "test_data2 = vectorized_asd_test_1.reshape(-1, 1)\n",
    "\n",
    "# Labels\n",
    "y_train = np.array([0]*594 + [1]*594)  # 0 for group 1 (NC), 1 for group 2 (ASD)\n",
    "y_test = np.array([0]*594 + [1]*594)\n",
    "\n",
    "# Combine data for training and testing\n",
    "X_train = np.vstack((train_data1, train_data2))\n",
    "X_test = np.vstack((test_data1, test_data2))\n",
    "\n",
    "# Train the SVM\n",
    "clf = SVC(kernel='linear', class_weight='balanced', probability=True)  # Enable probability for AUC\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on testing set and calculate metrics\n",
    "y_pred = clf.predict(X_test)\n",
    "y_prob = clf.decision_function(X_test)  # Get decision function for AUC\n",
    "\n",
    "# Basic evaluations\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)  # AUC calculation\n",
    "\n",
    "# Detailed evaluations\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Sensitivity: {sensitivity}')\n",
    "print(f'Specificity: {specificity}')\n",
    "print(f'F1 Score: {f1}')  # Print F1 score\n",
    "print(f'AUC Score: {auc}')  # Print AUC score\n",
    "# print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.45286195286195285\n",
    "Sensitivity: 0.7205387205387206\n",
    "Specificity: 0.18518518518518517\n",
    "F1 Score: 0.5683930942895087\n",
    "AUC Score: 0.4285475405004025\n",
    "Accuracy: 0.4595959595959596\n",
    "Sensitivity: 0.28619528619528617\n",
    "Specificity: 0.632996632996633\n",
    "F1 Score: 0.3462321792260693\n",
    "AUC Score: 0.5214944053327891\n",
    "Accuracy: 0.5235690235690236\n",
    "Sensitivity: 0.11952861952861953\n",
    "Specificity: 0.9276094276094277\n",
    "F1 Score: 0.2005649717514124\n",
    "AUC Score: 0.5653221326622\n",
    "\n",
    "Accuracy: 0.34595959595959597\n",
    "Sensitivity: 0.6531986531986532\n",
    "Specificity: 0.03872053872053872\n",
    "F1 Score: 0.49967804249839026\n",
    "AUC Score: 0.1579147252547926"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average one-shot performance over 100 trials:\n",
      "Accuracy: 0.43\n",
      "Sensitivity: 0.9512195121951219\n",
      "Specificity: 0.06779661016949153\n",
      "F1 Score: 0.5777777777777778\n",
      "AUC Score: 0.5095080611823067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# np.random.seed(35810)\n",
    "\n",
    "\n",
    "def random_one_shot_evaluation(X_test, y_test, clf, num_trials=50):\n",
    "    # Initialize lists to store predictions and actual labels\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    \n",
    "    for _ in range(num_trials):\n",
    "        # Randomly select an index from the test set\n",
    "        idx = np.random.randint(0, len(y_test))\n",
    "        \n",
    "        # Extract the feature vector and label for the selected index\n",
    "        X_one_shot = X_test[idx:idx+1, :]  # Keep it 2D\n",
    "        y_one_shot = y_test[idx]\n",
    "        \n",
    "        # Predict with SVM and store the result\n",
    "        y_pred_one_shot = clf.predict(X_one_shot)\n",
    "        \n",
    "        # Store predictions and actual labels\n",
    "        predictions.append(y_pred_one_shot[0])\n",
    "        actual_labels.append(y_one_shot)\n",
    "    \n",
    "    # Convert lists to arrays for metric calculation\n",
    "    predictions = np.array(predictions)\n",
    "    actual_labels = np.array(actual_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(actual_labels, predictions)\n",
    "    tn, fp, fn, tp = confusion_matrix(actual_labels, predictions).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1 = f1_score(actual_labels, predictions)\n",
    "    \n",
    "    # Calculate AUC if both classes are present in the actual labels\n",
    "    if len(np.unique(actual_labels)) == 2:\n",
    "        auc = roc_auc_score(actual_labels, predictions)\n",
    "    else:\n",
    "        auc = np.nan  # Not applicable if only one class\n",
    "    \n",
    "    return accuracy, sensitivity, specificity, f1, auc\n",
    "\n",
    "# Perform the random one-shot evaluation and calculate metrics\n",
    "accuracy, sensitivity, specificity, f1, auc = random_one_shot_evaluation(X_test, y_test, clf, num_trials=100)\n",
    "\n",
    "print(f\"Average one-shot performance over 100 trials:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"AUC Score: {auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.426930405048935 10.43961646296697 10.442686048648255\n",
      "0.016179695731160185 0.013593716885480367 0.020545098444905232\n"
     ]
    }
   ],
   "source": [
    "# adhd memory capacity\n",
    "one = [10.409617701040368, 10.411034982089031, 10.44967414304455, 10.441767005875718, 10.422558193195007]\n",
    "two = [10.435571587789113, 10.431826460427384, 10.453300147548715, 10.456829703702383, 10.420554415367254]\n",
    "three = [10.435011750356118, 10.422514266480796, 10.470782781130618, 10.42188160380818, 10.463239841465565]\n",
    "\n",
    "print( np.mean(one), np.mean(two), np.mean(three))\n",
    "print( np.std(one), np.std(two), np.std(three))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4136890810289214 0.40516486117904604 0.43215059028722785\n",
      "0.024864336961744036 0.012126986667394077 0.03374676839145833\n"
     ]
    }
   ],
   "source": [
    "# adhd biological mse\n",
    "one = [0.4094628761988274, 0.4154512901217365, 0.4240177141800689, 0.44804907976939573, 0.37146444487457825]\n",
    "two = [0.3937360636822037, 0.3980667383196679, 0.42823957726211526, 0.4052924756000258, 0.40048945103121764]\n",
    "three = [0.4255579089247809, 0.44296586301617125, 0.3729803368906557, 0.4434527385777433, 0.47579610402678774]\n",
    "\n",
    "print( np.mean(one), np.mean(two), np.mean(three))\n",
    "print( np.std(one), np.std(two), np.std(three))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.168 12.313597488403321 12.367999999999999\n",
      "0.09108238029388523 0.11760362630212454 0.13962807740565636\n"
     ]
    }
   ],
   "source": [
    "# adhd forbenius distance\n",
    "one = [12.08, 12.26, 12.07, 12.14, 12.29]\n",
    "two = [12.366154670715332, 12.356213569641113, 12.196998596191406, 12.48360538482666, 12.16501522064209]\n",
    "three = [12.36, 12.58, 12.37, 12.14, 12.39]\n",
    "\n",
    "print( np.mean(one), np.mean(two), np.mean(three))\n",
    "print( np.std(one), np.std(two), np.std(three))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.437014632304496 10.43008859697892 10.442543408579176\n",
      "0.008721805734139824 0.01636092480584422 0.02496497255756501\n"
     ]
    }
   ],
   "source": [
    "# lmci mc\n",
    "one = [10.430546612578768, 10.43664712364393, 10.425000097563931, 10.443578925365648, 10.449300402370204]\n",
    "two = [10.43850649611473, 10.445215849677727, 10.423382539859674, 10.401029818228869, 10.442308281013592]\n",
    "three = [10.422318665150017, 10.49088502979133, 10.426623383175018, 10.44105301195567, 10.43183695282385]\n",
    "\n",
    "print( np.mean(one), np.mean(two), np.mean(three))\n",
    "print( np.std(one), np.std(two), np.std(three))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4028357629677101 0.39747756546514423 0.38804915157777603\n",
      "0.011935032391064561 0.023561663946084804 0.039795430576490834\n"
     ]
    }
   ],
   "source": [
    "# lmci biological mse\n",
    "one = [0.39246991448409217, 0.4204667419668714, 0.387092625676081, 0.40932621970790695, 0.4048233130035988]\n",
    "two = [0.4116665726973487, 0.36661540042755536, 0.407220600810168, 0.3735289545032772, 0.4283562988873719]\n",
    "three = [0.366863380916897, 0.4548777554821604, 0.3383346501067925, 0.40626616917652764, 0.37390380220650233]\n",
    "\n",
    "\n",
    "print( np.mean(one), np.mean(two), np.mean(three))\n",
    "print( np.std(one), np.std(two), np.std(three))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.464 12.429999999999998 12.442000000000002\n",
      "0.2170345594600088 0.171813852759316 0.20701690752206706\n"
     ]
    }
   ],
   "source": [
    "# lmci forbenius distance\n",
    "one = [12.73, 12.65, 12.50, 12.29, 12.15]\n",
    "two = [12.60, 12.30, 12.51, 12.16, 12.58]\n",
    "three = [12.10, 12.65, 12.60, 12.55, 12.31]\n",
    "\n",
    "print( np.mean(one), np.mean(two), np.mean(three))\n",
    "print( np.std(one), np.std(two), np.std(three))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
